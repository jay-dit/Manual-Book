{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514d1a23",
   "metadata": {},
   "source": [
    "# Форматы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52abff7",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. \"Форматы данных\"\n",
    "* https://docs.python.org/3/library/json.html\n",
    "* https://docs.h5py.org/en/stable/\n",
    "* https://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/bs4ru.html\n",
    "* Уэс Маккини. Python и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7670e",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47459cc",
   "metadata": {},
   "source": [
    "1. Вывести телефоны, содержащиеся в адресной книге `addres-book.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317e0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    r\"03_data_files_data\\addres-book.json\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as fp:\n",
    "    # .... чего-то делаем\n",
    "    book = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663d7679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Faina Lee',\n",
       "  'email': 'faina@mail.ru',\n",
       "  'birthday': '22.08.1994',\n",
       "  'phones': [{'phone': '232-19-55'}, {'phone': '+7 (916) 232-19-55'}]},\n",
       " {'name': 'Robert Lee',\n",
       "  'email': 'robert@mail.ru',\n",
       "  'birthday': '22.08.1994',\n",
       "  'phones': [{'phone': '111-19-55'}, {'phone': '+7 (916) 445-19-55'}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7feade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['232-19-55', '+7 (916) 232-19-55', '111-19-55', '+7 (916) 445-19-55']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones = []\n",
    "\n",
    "for person in book:\n",
    "    phones.extend(ph[\"phone\"] for ph in person[\"phones\"])\n",
    "phones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f43ac",
   "metadata": {},
   "source": [
    "2. По данным из файла `addres-book-q.xml` сформировать список словарей с телефонами каждого из людей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d398315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'work', 'number': '+ (213) 6150 4015'},\n",
       " {'type': 'personal', 'number': '+ (213) 2173 5247'},\n",
       " {'type': 'work', 'number': '+ (244-2) 325 023'},\n",
       " {'type': 'personal', 'number': '+ (244-2) 325 023'},\n",
       " {'type': 'personal', 'number': '+ (244) 4232 2836'},\n",
       " {'type': 'work', 'number': '+ (244-2) 325 023'},\n",
       " {'type': 'personal', 'number': '+ (244-2) 325 023'},\n",
       " {'type': 'work', 'number': '+ (54-11) 4784 1159'},\n",
       " {'type': 'work', 'number': '+ (61-2) 6274 9500'},\n",
       " {'type': 'personal', 'number': '+ (61-2) 6274 9513'},\n",
       " {'type': 'work', 'number': '+ (61-3) 9807 4702'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\n",
    "    r\"03_data_files_data\\addres-book-q.xml\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as fp:\n",
    "    book = BeautifulSoup(fp)\n",
    "\n",
    "addresses = book.find_all(\"address\")\n",
    "address = addresses[0]\n",
    "phones = address.find_all(\"phone\")\n",
    "phone = phones[0]\n",
    "\n",
    "phones = []\n",
    "\n",
    "for address in addresses:\n",
    "    phones.extend({\"type\": ph[\"type\"], \"number\": ph.text} for ph in address.find_all(\"phone\"))\n",
    "phones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f507d",
   "metadata": {},
   "source": [
    "3. Создайте 2 матрицы размера 1000x1000, используя различные параметризируемые распределения из numpy (https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html#distributions)\n",
    "\n",
    "После этого сохраните получившиеся матрицы в hdf5-файл в виде двух различных датасетов. В качестве описания каждого датасета укажите параметры используемых распределений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36765ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['exp2', 'gr1']>\n",
      "<HDF5 dataset \"exp1\": shape (1000, 1000), type \"<f8\">\n",
      "[[1.47686713 0.04501563 0.91099547 ... 4.68139556 1.37240853 4.06499956]\n",
      " [0.72344896 3.70747659 1.22222605 ... 8.10468112 2.24924194 0.80962533]\n",
      " [0.16762837 1.65047069 0.008251   ... 2.00488281 1.57927609 2.07744004]\n",
      " ...\n",
      " [0.37105547 7.97880065 1.73734466 ... 0.21225129 4.64166867 0.26582638]\n",
      " [1.32837466 0.05297833 1.15234376 ... 1.50033969 2.06873579 5.5607743 ]\n",
      " [2.86341805 0.96908224 1.23894767 ... 0.99935194 1.14907149 0.26368513]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.47686713, 0.04501563, 0.91099547, ..., 4.68139556, 1.37240853,\n",
       "        4.06499956],\n",
       "       [0.72344896, 3.70747659, 1.22222605, ..., 8.10468112, 2.24924194,\n",
       "        0.80962533],\n",
       "       [0.16762837, 1.65047069, 0.008251  , ..., 2.00488281, 1.57927609,\n",
       "        2.07744004],\n",
       "       ...,\n",
       "       [0.37105547, 7.97880065, 1.73734466, ..., 0.21225129, 4.64166867,\n",
       "        0.26582638],\n",
       "       [1.32837466, 0.05297833, 1.15234376, ..., 1.50033969, 2.06873579,\n",
       "        5.5607743 ],\n",
       "       [2.86341805, 0.96908224, 1.23894767, ..., 0.99935194, 1.14907149,\n",
       "        0.26368513]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix1 = np.random.exponential(scale=2, size=(1000, 1000))\n",
    "matrix2 = np.random.exponential(scale=20, size=(1000, 1000))\n",
    "\n",
    "import h5py\n",
    "\n",
    "with h5py.File(\n",
    "    \"test.h5\",\n",
    "    \"w\"\n",
    ") as fp:\n",
    "    group1 = fp.create_group(\"gr1\")\n",
    "    exp1 = group1.create_dataset(\"exp1\", data=matrix1)\n",
    "    exp1.attrs[\"description\"] = \"Sample from exp. distr with scale 2\"\n",
    "    \n",
    "    exp2 = fp.create_dataset(\"exp2\", data=matrix2)\n",
    "    exp2.attrs[\"description\"] = \"Sample from exp. distr with scale 20\"\n",
    "\n",
    "# np.save()\n",
    "\n",
    "with h5py.File(\n",
    "    \"test.h5\",\n",
    "    \"r\"\n",
    ") as fp:\n",
    "    print(fp.keys())\n",
    "    exp1 = fp[\"gr1/exp1\"]\n",
    "    print(exp1)\n",
    "    data = exp1[:100, :100]\n",
    "    print(data)\n",
    "    \n",
    "# data2 = exp1[:100, :100]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc72c0",
   "metadata": {},
   "source": [
    "## Лабораторная работа №3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac60f59",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d80a7d",
   "metadata": {},
   "source": [
    "1.1 Считайте файл `contributors_sample.json`, воспользовавшись модулем `json` и свяжите загруженные данные с переменной `contributors`. Выведите на экран уникальные почтовые домены, содержащиеся в почтовых адресах людей. Под доменом понимается часть адреса, следующая за символом `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db6b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\n",
    "    r\"03_data_files_data\\contributors_sample.json\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as fp:\n",
    "    contributors = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39856334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@gmail.com', '@hotmail.com', '@yahoo.com'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = set()\n",
    "for el in contributors:\n",
    "    ind = el['mail'].find('@')\n",
    "    data.add(el['mail'][ind:])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef460b09",
   "metadata": {},
   "source": [
    "1.2 Посчитайте, как часто встречается та или иная должность во всем наборе данных. Выведите на экран 5 должностей, которые встречаются наиболее часто. Для каждого пользователя из `contributors` выясните, какая из его должностей является наиболее распространенной (в смысле частоты упоминания во всем датасете) и добавьте ключ `top_job`, в котором хранится название этой должности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a989117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_of_jobs = []\n",
    "for el in contributors:\n",
    "    sp_of_jobs.extend(el['jobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755f642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'job': sp_of_jobs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "827a2c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "= TOP 5 =\n",
      "=========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job                           \n",
       "Chemical engineer                 42\n",
       "Bookseller                        41\n",
       "Chief Operating Officer           41\n",
       "Telecommunications researcher     41\n",
       "Dance movement psychotherapist    41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\"\"=========\n",
    "= TOP 5 =\n",
    "=========\"\"\")\n",
    "df.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cf42c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_work(list_of_jobs, top):\n",
    "    return top[list_of_jobs].idxmax()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06f14bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'uhebert',\n",
       " 'name': 'Lindsey Nguyen',\n",
       " 'sex': 'F',\n",
       " 'address': '01261 Cameron Spring\\nTaylorfurt, AK 97791',\n",
       " 'mail': 'jsalazar@gmail.com',\n",
       " 'jobs': ['Energy engineer',\n",
       "  'Engineer, site',\n",
       "  'Environmental health practitioner',\n",
       "  'Biomedical scientist',\n",
       "  'Jewellery designer'],\n",
       " 'id': 35193,\n",
       " 'top_job': 'Environmental health practitioner'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for el in contributors:\n",
    "    el['top_job'] = top_work(el['jobs'], df.value_counts())\n",
    "contributors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6549b66",
   "metadata": {},
   "source": [
    "1.3 Создайте `pd.DataFrame` `contributors_df`, имеющий столбцы `id`, `username` и `sex` и `n_jobs`. Столбец `n_jobs` содержит кол-во должностей пользователя. При необходимости вы можете преобразовать исходные данные в списке `contributors` в удобный для создания `pd.DataFrame` вид.\n",
    "\n",
    "Сгруппируйте полученные данные по столбцам `n_jobs` и `sex`. Выведите на экран серию `pd.Series`, в которой содержится информация о количестве человек в каждой группе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abf60c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_df = {'id':[], 'username': [], 'sex': [], 'n_jobs': []}\n",
    "for el in contributors:\n",
    "    dict_for_df['id'].append(el['id'])\n",
    "    dict_for_df['username'].append(el['username'])\n",
    "    dict_for_df['sex'].append(el['sex'])\n",
    "    dict_for_df['n_jobs'].append(len(el['jobs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c98906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35193</td>\n",
       "      <td>uhebert</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91970</td>\n",
       "      <td>vickitaylor</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     username sex  n_jobs\n",
       "0  35193      uhebert   F       5\n",
       "1  91970  vickitaylor   F       3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_for_df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "534e8616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>F</th>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>F</th>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>F</th>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id\n",
       "n_jobs sex     \n",
       "3      F    703\n",
       "       M    690\n",
       "4      F    733\n",
       "       M    704\n",
       "5      F    700\n",
       "       M    670"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Слегонца не понял, что конктретно тут имелось ввиду под\n",
    "# сгруппировать\n",
    "# Я вижу так:\n",
    "df.groupby(['n_jobs', 'sex'])[['id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f85ad",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffaeb6",
   "metadata": {},
   "source": [
    "2.1 По данным файла `steps_sample.xml` сформируйте словарь с шагами по каждому рецепту вида `{id_рецепта: [\"шаг1\", \"шаг2\"]}`. Сохраните этот словарь в файл `steps_sample.json`. Выведите на экран шаги рецепта с id `84797`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750c8a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\n",
    "    r\"03_data_files_data\\steps_sample.xml\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as fp:\n",
    "    book = BeautifulSoup(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15ac26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_steps = {}\n",
    "for recipe in book.findAll('recipe'):\n",
    "    dict_for_steps[recipe.find('id').text] = [el.text for el in recipe.findAll('step')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19c88806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honey mustard sauce: whisk all the ingredients together serve warm or cold',\n",
       " 'easy bbq sauce: combine all ingredients in a pot& cook over low heat until the sugar is dissolved',\n",
       " 'serve warm or cold',\n",
       " 'garlic dill sauce: mix all the ingredients and chill until ready to serve']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_for_steps['84797']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70fbcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('steps_sample.json', 'w') as fp:\n",
    "    json.dump(dict_for_steps, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1653ec0",
   "metadata": {},
   "source": [
    "2.2 Получите список идентификаторов рецептов, в этапах выполнения которых есть информация о времени (часы или минуты). Для отбора подходящих рецептов обратите внимание на атрибуты соответствующих тэгов. Выведите на экран количество таких рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3a18f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23469\n"
     ]
    }
   ],
   "source": [
    "list_of_ind = set()\n",
    "for recipe in book.findAll('recipe'):\n",
    "    for step in recipe.findAll('step'):\n",
    "        if step.get('has_minutes') == '1' or step.get('has_hours') == '1' :\n",
    "            list_of_ind.add(recipe.find('id').text) \n",
    "list_of_ind = list(list_of_ind)\n",
    "print(len(list_of_ind))         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f68cb",
   "metadata": {},
   "source": [
    "2.3 Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в таблицу `recipes`. Для строк, которые содержат пропуски в столбце `n_steps`, заполните этот столбец на основе файла  `steps_sample.xml`. Строки, в которых столбец `n_steps` заполнен, оставьте без изменений. При решении задачи не используйте метод `iterrows` и аналогичные ему, позволяющие итерироваться по таблице построчно.\n",
    "\n",
    "Проверьте, содержит ли столбец `n_steps` пропуски. Если нет, то преобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_filled_nsteps.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "382c2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(r'C:\\Users\\voval\\YandexDisk\\Вуз\\ТОБД\\ТОБД22-ПМ20-Материалы к семинарам\\02_pandas\\02_pandas_data\\recipes_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f7ab906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\n",
    "    r\"03_data_files_data\\steps_sample.xml\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as fp:\n",
    "    book = BeautifulSoup(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ebeca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_df = {'id': [], 'n_steps':[]}\n",
    "for el in book.findAll('recipe'):\n",
    "    dict_for_df['id'].append(int(el.find('id').text))\n",
    "    dict_for_df['n_steps'].append(len(el.findAll('step')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "268bbd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44123</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67664</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "44123  11\n",
       "67664   3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_for_df['n_steps'], index=dict_for_df['id'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc2132eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_without_nan = recipes.loc[recipes['n_steps'].dropna().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9e9c55f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name     id  minutes  contributor_id  \\\n",
       "0  george s at the cove  black bean soup  44123       90           35193   \n",
       "1     healthy for them  yogurt popsicles  67664       10           91970   \n",
       "\n",
       "    submitted                                        description  \\\n",
       "0  2002-10-25  an original recipe created by chef scott meska...   \n",
       "1  2003-07-26  my children and their friends ask for my homem...   \n",
       "\n",
       "   n_ingredients  \n",
       "0           18.0  \n",
       "1            NaN  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_with_nan = recipes[np.isnan(recipes['n_steps'])]\n",
    "del recipes_with_nan['n_steps']\n",
    "recipes_with_nan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfccba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voval\\AppData\\Local\\Temp\\ipykernel_12496\\589716960.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recipes_with_nan['n_steps'] = np.array(df.loc[recipes_with_nan['id']])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name     id  minutes  contributor_id  \\\n",
       "0  george s at the cove  black bean soup  44123       90           35193   \n",
       "1     healthy for them  yogurt popsicles  67664       10           91970   \n",
       "\n",
       "    submitted                                        description  \\\n",
       "0  2002-10-25  an original recipe created by chef scott meska...   \n",
       "1  2003-07-26  my children and their friends ask for my homem...   \n",
       "\n",
       "   n_ingredients  n_steps  \n",
       "0           18.0       11  \n",
       "1            NaN        3  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_with_nan['n_steps'] = np.array(df.loc[recipes_with_nan['id']])\n",
    "recipes_with_nan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0f2e227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>38798</td>\n",
       "      <td>30</td>\n",
       "      <td>1533</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>35173</td>\n",
       "      <td>45</td>\n",
       "      <td>22724</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mennonite  corn fritters</td>\n",
       "      <td>44045</td>\n",
       "      <td>15</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>ok - my heritage has been revealed. :) these a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29989</th>\n",
       "      <td>zucchini cheddar casserole</td>\n",
       "      <td>74023</td>\n",
       "      <td>50</td>\n",
       "      <td>89831</td>\n",
       "      <td>2003-10-24</td>\n",
       "      <td>this has been a long time family favorite!</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>zucchini  courgette soup  good for weight watc...</td>\n",
       "      <td>415406</td>\n",
       "      <td>45</td>\n",
       "      <td>485109</td>\n",
       "      <td>2010-03-04</td>\n",
       "      <td>this is a favourite winter warmer. by british ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>zuppa by luisa</td>\n",
       "      <td>464576</td>\n",
       "      <td>70</td>\n",
       "      <td>226863</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>this soup is a hearty meal!  from luisa musso.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>267661</td>\n",
       "      <td>80</td>\n",
       "      <td>200862</td>\n",
       "      <td>2007-11-25</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>298512</td>\n",
       "      <td>29</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>i've heard of the 'cookies by design' company,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name      id  minutes  \\\n",
       "0                  george s at the cove  black bean soup   44123       90   \n",
       "1                     healthy for them  yogurt popsicles   67664       10   \n",
       "2                           i can t believe it s spinach   38798       30   \n",
       "3                                   italian  gut busters   35173       45   \n",
       "5                               mennonite  corn fritters   44045       15   \n",
       "...                                                  ...     ...      ...   \n",
       "29989                         zucchini cheddar casserole   74023       50   \n",
       "29992  zucchini  courgette soup  good for weight watc...  415406       45   \n",
       "29994                                     zuppa by luisa  464576       70   \n",
       "29995       zurie s holey rustic olive and cheddar bread  267661       80   \n",
       "29999             cookies by design   cookies on a stick  298512       29   \n",
       "\n",
       "       contributor_id   submitted  \\\n",
       "0               35193  2002-10-25   \n",
       "1               91970  2003-07-26   \n",
       "2                1533  2002-08-29   \n",
       "3               22724  2002-07-27   \n",
       "5               41706  2002-10-25   \n",
       "...               ...         ...   \n",
       "29989           89831  2003-10-24   \n",
       "29992          485109  2010-03-04   \n",
       "29994          226863  2011-09-20   \n",
       "29995          200862  2007-11-25   \n",
       "29999          506822  2008-04-15   \n",
       "\n",
       "                                             description  n_ingredients  \\\n",
       "0      an original recipe created by chef scott meska...           18.0   \n",
       "1      my children and their friends ask for my homem...            NaN   \n",
       "2                these were so go, it surprised even me.            8.0   \n",
       "3      my sister-in-law made these for us at a family...            NaN   \n",
       "5      ok - my heritage has been revealed. :) these a...            NaN   \n",
       "...                                                  ...            ...   \n",
       "29989         this has been a long time family favorite!            8.0   \n",
       "29992  this is a favourite winter warmer. by british ...            NaN   \n",
       "29994     this soup is a hearty meal!  from luisa musso.           17.0   \n",
       "29995  this is based on a french recipe but i changed...           10.0   \n",
       "29999  i've heard of the 'cookies by design' company,...           10.0   \n",
       "\n",
       "       n_steps  \n",
       "0         11.0  \n",
       "1          3.0  \n",
       "2          5.0  \n",
       "3          7.0  \n",
       "5          6.0  \n",
       "...        ...  \n",
       "29989     14.0  \n",
       "29992      5.0  \n",
       "29994     14.0  \n",
       "29995     16.0  \n",
       "29999      9.0  \n",
       "\n",
       "[30000 rows x 8 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([recipes_with_nan, recipes_without_nan])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a0fff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67664</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84797</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  n_steps\n",
       "1  67664      NaN\n",
       "4  84797      4.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.loc[[1,4], ['id', 'n_steps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "207e8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67664</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84797</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  n_steps\n",
       "1  67664      3.0\n",
       "4  84797      4.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[[1,4], ['id', 'n_steps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "36d6daba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['n_steps'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2e745615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name               object\n",
       "id                  int64\n",
       "minutes             int64\n",
       "contributor_id      int64\n",
       "submitted          object\n",
       "description        object\n",
       "n_ingredients     float64\n",
       "n_steps             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.astype({'n_steps': 'int32'})\n",
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2b44e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('recipes_sample_with_filled_nsteps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd86e69",
   "metadata": {},
   "source": [
    "### hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde1ab6",
   "metadata": {},
   "source": [
    "3.1 Выведите названия всех датасетов, находящихся в файле `nutrition_sample.h5`, а также размерность матриц, содержащихся в данных датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
    "Dataset name=dataset_1 n_rows=30000 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "Dataset name=dataset_2 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sugar (PDV)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b053da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
      "Dataset name=dataset_1 n_rows=30000 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
      "Dataset name=dataset_2 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sugar (PDV)\n",
      "Dataset name=dataset_3 n_rows=30000 n_cols=2 col_0=recipe_id col_1=sodium (PDV)\n",
      "Dataset name=dataset_4 n_rows=30000 n_cols=2 col_0=recipe_id col_1=protein (PDV)\n",
      "Dataset name=dataset_5 n_rows=30000 n_cols=2 col_0=recipe_id col_1=saturated fat (PDV)\n",
      "Dataset name=dataset_6 n_rows=30000 n_cols=2 col_0=recipe_id col_1=carbohydrates (PDV)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(r'03_data_files_data\\nutrition_sample.h5', 'r') as f:\n",
    "    for key in f.keys():\n",
    "        attr_keys = list(f[key].attrs.keys())\n",
    "        \n",
    "        print(f'Dataset name={key} n_rows={f[key][:].shape[0]} n_cols={f[key][:].shape[1]} {attr_keys[0]}={f[key].attrs[attr_keys[0]]} {attr_keys[1]}={f[key].attrs[attr_keys[1]]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc9790",
   "metadata": {},
   "source": [
    "3.2 Разбейте каждый из имеющихся датасетов на две части: 1 часть содержит только те строки, где PDV (Percent Daily Value) превышает 100%; 2 часть содержит те строки, где PDV составляет не более 100%. Создайте 2 группы в файле и разместите в них соответствующие части датасета c сохранением метаданных исходных датасетов. Итого должно получиться 2 группы, содержащие несколько датасетов. Датасеты, которые не содержат информацию о PDV, оставьте вне групп. Сохраните результаты в файл `nutrition_grouped.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8bc657dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset_1',\n",
       " array([[4.41230e+04, 1.08000e+02],\n",
       "        [8.47970e+04, 1.54000e+02],\n",
       "        [5.06620e+04, 3.25000e+02],\n",
       "        ...,\n",
       "        [8.00670e+04, 1.29000e+02],\n",
       "        [7.14500e+04, 2.37000e+02],\n",
       "        [2.67661e+05, 2.42000e+02]]),\n",
       " array([[6.76640e+04, 3.00000e+00],\n",
       "        [3.87980e+04, 5.00000e+00],\n",
       "        [3.51730e+04, 1.00000e+02],\n",
       "        ...,\n",
       "        [1.03312e+05, 8.70000e+01],\n",
       "        [4.86161e+05, 2.60000e+01],\n",
       "        [2.98512e+05, 1.10000e+01]]),\n",
       " ['col_0', 'col_1'],\n",
       " ['recipe_id', 'total fat (PDV)']]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "not_df = []\n",
    "with h5py.File(r'03_data_files_data\\nutrition_sample.h5', 'r') as f:\n",
    "    for key in f.keys():\n",
    "        if '(PDV)' in f[key].attrs['col_1']:\n",
    "            new_dataset = [key]\n",
    "            new_dataset.append(f[key][f[key][:,1]>100])\n",
    "            new_dataset.append(f[key][f[key][:,1]<=100])\n",
    "            t1 = []\n",
    "            t2 = []\n",
    "            for el in f[key].attrs.keys():\n",
    "                t1.append(el)\n",
    "                t2.append(f[key].attrs[el])\n",
    "            new_dataset.append(t1)\n",
    "            new_dataset.append(t2)\n",
    "            datasets.append(new_dataset)\n",
    "        else:\n",
    "            new_dataset = [key]\n",
    "            new_dataset.append(f[key][:])\n",
    "            t1 = []\n",
    "            t2 = []\n",
    "            for el in f[key].attrs.keys():\n",
    "                t1.append(el)\n",
    "                t2.append(f[key].attrs[el])\n",
    "            new_dataset.append(t1)\n",
    "            new_dataset.append(t2)\n",
    "            not_df.append(new_dataset)\n",
    "\n",
    "datasets[0]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5fe1ba20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dataset_0',\n",
       "  array([[4.41230e+04, 8.04700e+02],\n",
       "         [6.76640e+04, 1.64600e+02],\n",
       "         [3.87980e+04, 5.38000e+01],\n",
       "         ...,\n",
       "         [1.03312e+05, 8.64100e+02],\n",
       "         [4.86161e+05, 4.15200e+02],\n",
       "         [2.98512e+05, 1.88000e+02]]),\n",
       "  ['col_0', 'col_1'],\n",
       "  ['recipe_id', 'calories (#)']]]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "13343630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(r'nutrition_grouped.h5', 'w') as f:\n",
    "    g1 = f.create_group(\"over_100\")\n",
    "    g2 = f.create_group(\"not_over_100\")\n",
    "\n",
    "    for el in datasets:\n",
    "        d1 = g1.create_dataset(el[0], data = el[1])\n",
    "        d2 = g2.create_dataset(el[0], data = el[2])\n",
    "        d1.attrs[el[3][0]] = el[4][0]\n",
    "        d1.attrs[el[3][1]] = el[4][1]\n",
    "        d2.attrs[el[3][0]] = el[4][0]\n",
    "        d2.attrs[el[3][1]] = el[4][1]\n",
    "    for el in not_df:\n",
    "        d1 = f.create_dataset(el[0], data = el[1])\n",
    "        d1.attrs[el[2][0]] = el[3][0]\n",
    "        d1.attrs[el[2][1]] = el[3][1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bb67a",
   "metadata": {},
   "source": [
    "3.3 Выведите названия всех групп и датасетов, находящихся в этих группах, из файла `nutrition_grouped.h5` а также размерность матриц, содержащихся в датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
    "Group less_equal_than_100:\n",
    "    Dataset name=less_equal_than_100/dataset_1 n_rows=28264 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "    ....\n",
    "Group more_than_100\n",
    "    Dataset name=more_than_100/dataset_1 n_rows=1736 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
    "    ....\n",
    "....\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a3638d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name=dataset_0 n_rows=30000 n_cols=2 col_0=recipe_id col_1=calories (#)\n",
      "Group not_over_100\n",
      "\tDataset name=dataset_1 n_rows=28264 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
      "\tDataset name=dataset_2 n_rows=24684 n_cols=2 col_0=recipe_id col_1=sugar (PDV)\n",
      "\tDataset name=dataset_3 n_rows=28756 n_cols=2 col_0=recipe_id col_1=sodium (PDV)\n",
      "\tDataset name=dataset_4 n_rows=28224 n_cols=2 col_0=recipe_id col_1=protein (PDV)\n",
      "\tDataset name=dataset_5 n_rows=27142 n_cols=2 col_0=recipe_id col_1=saturated fat (PDV)\n",
      "\tDataset name=dataset_6 n_rows=29358 n_cols=2 col_0=recipe_id col_1=carbohydrates (PDV)\n",
      "Group over_100\n",
      "\tDataset name=dataset_1 n_rows=1736 n_cols=2 col_0=recipe_id col_1=total fat (PDV)\n",
      "\tDataset name=dataset_2 n_rows=5316 n_cols=2 col_0=recipe_id col_1=sugar (PDV)\n",
      "\tDataset name=dataset_3 n_rows=1244 n_cols=2 col_0=recipe_id col_1=sodium (PDV)\n",
      "\tDataset name=dataset_4 n_rows=1776 n_cols=2 col_0=recipe_id col_1=protein (PDV)\n",
      "\tDataset name=dataset_5 n_rows=2858 n_cols=2 col_0=recipe_id col_1=saturated fat (PDV)\n",
      "\tDataset name=dataset_6 n_rows=642 n_cols=2 col_0=recipe_id col_1=carbohydrates (PDV)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'nutrition_grouped.h5', 'r') as f:\n",
    "    for key in f.keys():\n",
    "\n",
    "        if isinstance(f[key], h5py._hl.dataset.Dataset):\n",
    "            attr_keys = list(f[key].attrs.keys())\n",
    "            print(f'Dataset name={key} n_rows={f[key][:].shape[0]} n_cols={f[key][:].shape[1]} {attr_keys[0]}={f[key].attrs[attr_keys[0]]} {attr_keys[1]}={f[key].attrs[attr_keys[1]]}')\n",
    "        if isinstance(f[key], h5py._hl.group.Group):\n",
    "            print(f'Group {key}')\n",
    "            g = f[key]\n",
    "            for key in g.keys():\n",
    "                attr_keys = list(g[key].attrs.keys())\n",
    "                print(f'\\tDataset name={key} n_rows={g[key][:].shape[0]} n_cols={g[key][:].shape[1]} {attr_keys[0]}={g[key].attrs[attr_keys[0]]} {attr_keys[1]}={g[key].attrs[attr_keys[1]]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ba061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "64df86e3fae60c44e1134cecfb7a61663684f188b1337634634fbf2fe53591c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
